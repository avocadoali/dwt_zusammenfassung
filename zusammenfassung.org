#+TITLE: Zusammenfassung
#+author: Mihir Mahajan, Alfred Nguyen, Noah Kiefer Diaz

* Diskrete Wahrscheinlichkeitsräume
** Grundlagen

*** Definition 1
- Ein diskreter Wahrscheinlichkeitsraum ist durch eine *Ergebnismenge* $\Omega = \{\omega_1,...,\omega_n\}$ von Elementarereignissen gegeben
- Jedem Ereignis $\omega_i4 ist eine Wahrscheinlichkeit $0 \leq Pr[\omega_i] \leq 1$ zugeordnet \\
  $\sum_{\omega \in \Omega} Pr[\omega]= 1$
- Die Menge $E \subseteq \Omega$ heißt Ereignis. $Pr[E] = \sum_{\omega \in E} Pr[\omega]$
- $\bar{E}$ ist komplement zu E


Man kann standard Mengenoperationen auf Ereignisse machen, also bei Ereignissen $A,B$ dann auch $A \cup B$, $A \cap B$

*** Lemma 8
Für Ereignisse $A,B, A_1, A_2,...,A_n$ gilt
- $Pr[\emptyset] = 0, Pr[\Omega] = 1$
- $0 \leq Pr[A] \leq 1$
- $Pr[\bar{A}] = 1 - Pr[A]$
- Wenn $A \subseteq B$ so folgt $Pr[A] \leq Pr[B]$
- Additionssatz: Bei *paarweise disjunkten* Ereignissen gilt: \\
  $Pr[\bigcup^{n}_{i=1} A_i] = \sum^n_{i=1} Pr[A_i]$ \\
  Insbesondere gilt also:\\
  $Pr[A \cup B] = Pr[A] + Pr[B]$ \\
  Und für unendliche Menge von *disjunkten* Ereignissen:\\
  $Pr[\bigcup^{\infty}_{i=1} A_i] = \sum^{\infty}_{i=1} Pr[A_i]$ \\

*** Satz 9 Siebformel
Lemma 8, gilt nur für *disjunkte* Mengen. Das geht auch für nicht disjunkte!
**** Zwei Mengen
$Pr[A \cup B] = Pr[A] + Pr[B] - Pr[A \cap B]$
**** Drei Mengen
$Pr[A_1 \cup A_2 \cup A_3] =$ \\
$Pr[A1] + Pr[A2] + Pr[A3]$ \\
$- Pr[A1 \cap A2] - Pr[A1 \cap A3] - Pr[A_2 \cap A_3$ \\
$+ Pr[A_1 \cap A_2 \cap A_3]$
**** n Mengen
Veranschaulichen an Venn-Diagramm
1. Alle aufaddieren
2. Paarweise schnitte subtrahieren
3. Dreifache schnitte dazuaddieren
4. 4- fache schritte subtrahieren
5. ...
**** für nerds:
$Pr[\bigcup_{i=0}^n  A_i] = \sum_{\emptyset \subset I \subseteq [n]} (-1)^{|I|+1}Pr[\bigcap_{i \in I} A_i]$

*** Wahl der Wahrscheinlichkeiten
Prinzip von Laplace (Pierre Simon Laplace (1749–1827)): Wenn nichts dagegen spricht, gehen wir davon aus, dass alle Elementarereignisse gleich wahrscheinlich sind.
$Pr[E] = \frac{|E|}{|\Omega|}$

** Bedingte Wahrscheinlichkeiten
*** Definition 12
$A$ und $B$ seien Ereignisse mit $Pr[B] > 0$. Die bedingte Wahrscheinlichkeit $Pr[A|B]$ von A gegeben B ist definiert als:
$Pr[A|B] := \frac{Pr[A \cap B]}{Pr[B]}$

Umgangssprachlich: $Pr[A|B]$ beschreibt die Wahrscheinlichkeit, dass A eintritt wenn B eintritt.

Die bedingten Wahrscheinlichkeiten $Pr[·|B]$ bilden für ein beliebiges Ereignis $B \subseteq \Omega$ mit $Pr[B] > 0$ einen neuen Wahrscheinlichkeitsraum über $\Omega$.


*** Baba Beispiele
**** TODO Töchterproblem
**** TODO Ziegenproblem
**** TODO Geburtstagsproblem

*** Satz 18 (Satz von der totalen Wahrscheinlichkeit)
Die Ereignisse $A_1, ..., An$ seien paarweise disjunkt und es gelte $B \subseteq A1 \cup ... \cup An$. \\
$Pr[B] = \sum_{i=1}^n Pr[B|A_i] * Pr[A_i]$ \\
analog für $n \rightarrow \infty$

*** Satz 19 (Satz von Bayes)
Es seien $A_1, ..., A_n$ paarweise disjunkt, mit $Pr[A_j] > 0$ für alle j.
Außerdem sei $B \subseteq A_1 \cup ... \cup A_n$ ein Ereignis mit $Pr[B]>0$.
Dann gilt für beliebiges $i \in [n]$

$Pr[A_i|B] = \frac{Pr[A_i \cap B]}{Pr[B]} = \frac{Pr[B|A_i] * Pr[A_i]}{\sum_{j=1}^n Pr[B|A_j] * Pr[A_j]}$

* Unabhängigkeit
 Wenn das auftreten von Ereignissen unabhängig ist.
 - $Pr[A \cap B] = Pr[A] * Pr[B]$
 - $Pr[A|B] = Pr[A]$

* Zufallsvariablen

** Grundlagen
Anstatt der Ereignisse selbst sind wir oft an ”Auswirkungen“ oder ”Merkmalen“ der (Elementarereignisse) interessiert

Sei ein Wahrscheinlichkeitsraum auf der Ergebnismenge Ω gegeben. Eine Abbildung $X : \Omega \rightarrow R$ heißt (numerische) Zufallsvariable.
Eine Zufallsvariable X über einer endlichen oder abzählbar unendlichen Ergebnismenge heißt *diskret*


** Erwartungswert und Varianz
*** Definition 29
Zu einer Zufalls variablen /X/ definieren wir den *Erwartungswert* $E[X]$ durch
$E[X] := \sum_{x\in W_X} x \ast Pr[X = x] = \sum x \ast f_X(x)$
sofern $\sum_{x\in W_X} |x| \ast Pr[X = x]$ konvergiert

*** Satz 32 Monotonie des Erwartungswerts
Seien X und Y Zufallsvariablen über dem Wahrscheinlichkeitsraum $\omega$ mit $X(\omega) \leq Y(\omega)$ für alle $\omega \in \Omega$. Dann gilt $\mathbb{E}[X] \leq \mathbb{E}[Y]$
$\mathbb{E}[X] = \sum_{\omega \in \Omega} X(\omega) * Pr[\omega] \leq \sum_{\omega \in \Omega} Y(\omega) * Pr[\omega] = \mathbb{E}[Y]$

*** Rechenregeln für Erwartungswert
Oft betrachtet man eine Zufallsvariable X nicht direkt, sondern wendet noch eine Funktion darauf an:
$Y := f(X) = f \circ X$ , \\
wobei $f : D \rightarrow R$ eine beliebige Funktion sei mit $W_X \subseteq D \subseteq R$.
Beobachtung: $f(X)$ ist wieder eine Zufallsvariable.

*** Satz 33 (Linearität des Erwartungswerts, einfache Version)
Für eine beliebige Zufallsvariable $X$ und $a, b \in R$ gilt\\
$\mathbb{E}[a * X + b] = a * \mathbb{E}[X] + b$

*** Satz 34
Sei $X$ eine Zufallsvariable mit $W_x \subseteq \mathbb{N}_0$. Dann gilt\\
$\mathbb{E}[X] = \sum_{i=1}^\infty Pr[X \geq i]$

*** Satz 35
Sei $X$ eine Zufallsvariable und A ein Ereignis mit $Pr[A] > 0$. Die *bedingte Zufallsvariable* $X|A$ besitzt die Dichte:\\
$f_{X|A}(x) := Pr[X=x|A] = \frac{Pr["X=x" \cap A]}{Pr[A]}$ \\
Die Definition ist zulässig, da \\
$\sum_{x \in W_x} f_{X|A}(x) = \sum_{x \in W_x} \frac{Pr["X=x" \cap A]}{Pr[A]} = 1$ \\
Somit ist $\mathbb{E}[X|A] = \sum_{x \in W_x} x * f_{X|A}(x)$

*** Satz 36
TODO

*** Varianz
**** Definition 38
Für eine Zufallsvariable X mit $\mu = E[X]$ definieren wir die Varianz $Var[X]$ durch \\
$Var[X] := E[(X − \mu)^2] = \sum_{x \in W_X}(x − \mu)^2 * Pr[X = x]$ \\
Die Größe $\sigma := \sqrt{Var[X]}$ \\
Var[X] heißt Standardabweichung von X.
**** Satz 39
Für eine beliebige Zufallsvariable $X$ gilt \\
$Var[X] = \mathbb{E}[X^2] - \mathbb{E}[X]^2$
**** Satz 41
Für eine beliebige Zufallsvariable $X$ und $a,b \in \mathbb{R}$ gilt:\\
$Var[a*X+b]=a^2*Var[X]$

** Mehrere Zufallsvariablen
Wie kann man mit mehreren Zufallsvariablen über demselben Wahrscheinlichkeitsraum rechnen, auch wenn sie, wie im obigen Beispiel, sehr voneinander abhängig sind?
Wir untersuchen Wahrscheinlichkeiten der Art \\
$Pr[X = x, Y = y] = Pr[{\omega; X(\omega) = x, Y (\omega)) = y\}]$

*** hypergeometrische Verteilung
Allgemein nennt man Zufallsvariablen mit der Dichte
$Pr[X = x] = \frac{\begin{pmatrix}b \\ x \end{pmatrix} * \begin{pmatrix} a \\ r-x \end{pmatrix}}{\begin{pmatrix}a+b \\ r \end{pmatrix}}$
*hypergeometrisch verteilt*. Durch diese Dichte wird ein Experiment modelliert, bei dem r Elemente ohne Zurücklegen aus einer Grundmenge der Mächtigkeit a + b mit b besonders ausgezeichneten Elementen gezogen werden.

*** Gemeinsame Dichte
Die Funktion \\
$f_{X,Y} (x, y) := Pr[X = x, Y = y]$
heißt gemeinsame Dichte der Zufallsvariablen X und Y. \\
Aus der gemeinsamen Dichte $f_{X,Y}$ kann man ableiten \\
$f_X(x) = \sum_{y \in W_Y} f_{X,Y} (x,y)$ \\
$f_Y(x) = \sum_{x \in W_X} f_{X,Y} (x,y)$ \\
Die Funktionen f_X und f_Y nennt man Randdichten. \\
*** Unabhängigkeit von Zufallsvariablen
**** Definition 45
Die Zufallsvariablen $X_1,...,X_n$ heißen unabhängig, wenn für alle $(x_1,...x_n) \in W_{X_1} \times ... \times W_{X_n}$ gilt: \\
$Pr[X_1 = x_1,...,X_n = x_n] = Pr[X_1 = x_1] * ... * Pr[X_n = x_n]$

Analog: Gesamte Dichte ist Produkt aus einzelnen Dichten.
Analog: Gesamte Verteilung ist Produkt aus einzelnen Verteilungen.

*** Zusammengesetzte Zufallsvariablen
**** Satz 49
Für zwei unabhängige Zufallsvariablen X und Y sei Z := X + Y . Es gilt
$f_Z(z) = \sum_{x \in W_X} f_X(x) * f_Y(z − x)$

*** Momente zusammengesetzter Zufallsvariablen
**** Satz 50 (Linearität des Erwartungswerts)
Für Zufallsvariablen $X_1,...,X_n$ und $X:=a_1X_1 + ... + a_nX_n$ mit $a_1, ...a_n \in R$ gilt \\
$\mathbb{E}[X] = a_1 \mathbb{E}[X_1]+ ... + a_n\mathbb{E}[X_n]$

**** Satz 52 (Multiplikativität des Erwartungswerts)
Für unabhängige Zufallsvariablen $X_1,..., X_n$ gilt
$E[X1*...*Xn] = E[X1]*...*E[Xn]$

**** Definition 53
Zu einem Ereignis A heißt die Zufallsvariable \\
$I_A = \begin{array}{ll}  1 & \, \textrm{falls A eintritt} \\ 0 & \, \textrm{sonst} \\\end{array}$ \\
*Indikatorvariable* des Ereigniss A
