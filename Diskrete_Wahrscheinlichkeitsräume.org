#+TITLE: Diskrete Wahrscheinlichkeitsräume
#+author: Mihir Mahajan, Alfred Nguyen, Noah Kiefer Diaz

* Diskrete Wahrscheinlichkeitsräume
** Grundlagen

*** Definition 1
- Ein diskreter Wahrscheinlichkeitsraum ist durch eine *Ergebnismenge* $\Omega = \{\omega_1,...,\omega_n\}$ von Elementarereignissen gegeben
- Jedem Ereignis $\omega_i4 ist eine Wahrscheinlichkeit $0 \leq Pr[\omega_i] \leq 1$ zugeordnet \\
  $\sum_{\omega \in \Omega} Pr[\omega]= 1$
- Die Menge $E \subseteq \Omega$ heißt Ereignis. $Pr[E] = \sum_{\omega \in E} Pr[\omega]$
- $\bar{E}$ ist komplement zu E


Man kann standard Mengenoperationen auf Ereignisse machen, also bei Ereignissen $A,B$ dann auch $A \cup B$, $A \cap B$

*** Lemma 8
Für Ereignisse $A,B, A_1, A_2,...,A_n$ gilt
- $Pr[\emptyset] = 0, Pr[\Omega] = 1$
- $0 \leq Pr[A] \leq 1$
- $Pr[\bar{A}] = 1 - Pr[A]$
- Wenn $A \subseteq B$ so folgt $Pr[A] \leq Pr[B]$
- Additionssatz: Bei *paarweise disjunkten* Ereignissen gilt: \\
  $Pr[\bigcup^{n}_{i=1} A_i] = \sum^n_{i=1} Pr[A_i]$ \\
  Insbesondere gilt also:\\
  $Pr[A \cup B] = Pr[A] + Pr[B]$ \\
  Und für unendliche Menge von *disjunkten* Ereignissen:\\
  $Pr[\bigcup^{\infty}_{i=1} A_i] = \sum^{\infty}_{i=1} Pr[A_i]$ \\

*** Satz 9 Siebformel
Lemma 8, gilt nur für *disjunkte* Mengen. Das geht auch für nicht disjunkte!
**** Zwei Mengen
$Pr[A \cup B] = Pr[A] + Pr[B] - Pr[A \cap B]$
**** Drei Mengen
$Pr[A_1 \cup A_2 \cup A_3] =$ \\
$Pr[A1] + Pr[A2] + Pr[A3]$ \\
$- Pr[A1 \cap A2] - Pr[A1 \cap A3] - Pr[A_2 \cap A_3$ \\
$+ Pr[A_1 \cap A_2 \cap A_3]$
**** n Mengen
Veranschaulichen an Venn-Diagramm
1. Alle aufaddieren
2. Paarweise schnitte subtrahieren
3. Dreifache schnitte dazuaddieren
4. 4- fache schritte subtrahieren
5. ...
**** für nerds:
$Pr[\bigcup_{i=0}^n  A_i] = \sum_{\emptyset \subset I \subseteq [n]} (-1)^{|I|+1}Pr[\bigcap_{i \in I} A_i]$

*** Wahl der Wahrscheinlichkeiten
Prinzip von Laplace (Pierre Simon Laplace (1749–1827)): Wenn nichts dagegen spricht, gehen wir davon aus, dass alle Elementarereignisse gleich wahrscheinlich sind.
$Pr[E] = \frac{|E|}{|\Omega|}$

** Bedingte Wahrscheinlichkeiten
*** Definition 12
$A$ und $B$ seien Ereignisse mit $Pr[B] > 0$. Die bedingte Wahrscheinlichkeit $Pr[A|B]$ von A gegeben B ist definiert als:
$Pr[A|B] := \frac{Pr[A \cap B]}{Pr[B]}$

Umgangssprachlich: $Pr[A|B]$ beschreibt die Wahrscheinlichkeit, dass A eintritt wenn B eintritt.

Die bedingten Wahrscheinlichkeiten $Pr[·|B]$ bilden für ein beliebiges Ereignis $B \subseteq \Omega$ mit $Pr[B] > 0$ einen neuen Wahrscheinlichkeitsraum über $\Omega$.


*** Baba Beispiele
**** TODO Töchterproblem
**** TODO Ziegenproblem
**** TODO Geburtstagsproblem

*** Satz 18 (Satz von der totalen Wahrscheinlichkeit)
Die Ereignisse $A_1, ..., An$ seien paarweise disjunkt und es gelte $B \subseteq A1 \cup ... \cup An$. \\
$Pr[B] = \sum_{i=1}^n Pr[B|A_i] * Pr[A_i]$ \\
analog für $n \rightarrow \infty$

*** Satz 19 (Satz von Bayes)
Es seien $A_1, ..., A_n$ paarweise disjunkt, mit $Pr[A_j] > 0$ für alle j.
Außerdem sei $B \subseteq A_1 \cup ... \cup A_n$ ein Ereignis mit $Pr[B]>0$.
Dann gilt für beliebiges $i \in [n]$

$Pr[A_i|B] = \frac{Pr[A_i \cap B]}{Pr[B]} = \frac{Pr[B|A_i] * Pr[A_i]}{\sum_{j=1}^n Pr[B|A_j] * Pr[A_j]}$

* Unabhängigkeit
 Wenn das auftreten von Ereignissen unabhängig ist.
 - $Pr[A \cap B] = Pr[A] * Pr[B]$
 - $Pr[A|B] = Pr[A]$

* Zufallsvariablen

** Grundlagen
Anstatt der Ereignisse selbst sind wir oft an ”Auswirkungen“ oder ”Merkmalen“ der (Elementarereignisse) interessiert

Sei ein Wahrscheinlichkeitsraum auf der Ergebnismenge Ω gegeben. Eine Abbildung $X : \Omega \rightarrow R$ heißt (numerische) Zufallsvariable.
Eine Zufallsvariable X über einer endlichen oder abzählbar unendlichen Ergebnismenge heißt *diskret*


** Erwartungswert und Varianz
*** Definition 29
Zu einer Zufalls variablen /X/ definieren wir den *Erwartungswert* $E[X]$ durch
$E[X] := \sum_{x\in W_X} x \ast Pr[X = x] = \sum x \ast f_X(x)$
sofern $\sum_{x\in W_X} |x| \ast Pr[X = x]$ konvergiert

*** Satz 32 Monotonie des Erwartungswerts
Seien X und Y Zufallsvariablen über dem Wahrscheinlichkeitsraum $\omega$ mit $X(\omega) \leq Y(\omega)$ für alle $\omega \in \Omega$. Dann gilt $\mathbb{E}[X] \leq \mathbb{E}[Y]$
$\mathbb{E}[X] = \sum_{\omega \in \Omega} X(\omega) * Pr[\omega] \leq \sum_{\omega \in \Omega} Y(\omega) * Pr[\omega] = \mathbb{E}[Y]$

*** Rechenregeln für Erwartungswert
Oft betrachtet man eine Zufallsvariable X nicht direkt, sondern wendet noch eine Funktion darauf an:
$Y := f(X) = f \circ X$ , \\
wobei $f : D \rightarrow R$ eine beliebige Funktion sei mit $W_X \subseteq D \subseteq R$.
Beobachtung: $f(X)$ ist wieder eine Zufallsvariable.

*** Satz 33 (Linearität des Erwartungswerts, einfache Version)
Für eine beliebige Zufallsvariable $X$ und $a, b \in R$ gilt\\
$\mathbb{E}[a * X + b] = a * \mathbb{E}[X] + b$

*** Satz 34
Sei $X$ eine Zufallsvariable mit $W_x \subseteq \mathbb{N}_0$. Dann gilt\\
$\mathbb{E}[X] = \sum_{i=1}^\infty Pr[X \geq i]$

*** Satz 35
Sei $X$ eine Zufallsvariable und A ein Ereignis mit $Pr[A] > 0$. Die *bedingte Zufallsvariable* $X|A$ besitzt die Dichte:\\
$f_{X|A}(x) := Pr[X=x|A] = \frac{Pr["X=x" \cap A]}{Pr[A]}$ \\
Die Definition ist zulässig, da \\
$\sum_{x \in W_x} f_{X|A}(x) = \sum_{x \in W_x} \frac{Pr["X=x" \cap A]}{Pr[A]} = 1$ \\
Somit ist $\mathbb{E}[X|A] = \sum_{x \in W_x} x * f_{X|A}(x)$

*** Satz 36
TODO

*** Varianz
**** Definition 38
Für eine Zufallsvariable X mit $\mu = E[X]$ definieren wir die Varianz $Var[X]$ durch \\
$Var[X] := E[(X − \mu)^2] = \sum_{x \in W_X}(x − \mu)^2 * Pr[X = x]$ \\
Die Größe $\sigma := \sqrt{Var[X]}$ \\
Var[X] heißt Standardabweichung von X.
**** Satz 39
Für eine beliebige Zufallsvariable $X$ gilt \\
$Var[X] = \mathbb{E}[X^2] - \mathbb{E}[X]^2$
**** Satz 41
Für eine beliebige Zufallsvariable $X$ und $a,b \in \mathbb{R}$ gilt:\\
$Var[a*X+b]=a^2*Var[X]$

** Mehrere Zufallsvariablen
Wie kann man mit mehreren Zufallsvariablen über demselben Wahrscheinlichkeitsraum rechnen, auch wenn sie, wie im obigen Beispiel, sehr voneinander abhängig sind?
Wir untersuchen Wahrscheinlichkeiten der Art \\
$Pr[X = x, Y = y] = Pr[{\omega; X(\omega) = x, Y (\omega)) = y\}]$

*** hypergeometrische Verteilung
Allgemein nennt man Zufallsvariablen mit der Dichte
$Pr[X = x] = \frac{\begin{pmatrix}b \\ x \end{pmatrix} * \begin{pmatrix} a \\ r-x \end{pmatrix}}{\begin{pmatrix}a+b \\ r \end{pmatrix}}$
*hypergeometrisch verteilt*. Durch diese Dichte wird ein Experiment modelliert, bei dem r Elemente ohne Zurücklegen aus einer Grundmenge der Mächtigkeit a + b mit b besonders ausgezeichneten Elementen gezogen werden.

*** Gemeinsame Dichte
Die Funktion \\
$f_{X,Y} (x, y) := Pr[X = x, Y = y]$
heißt gemeinsame Dichte der Zufallsvariablen X und Y. \\
Aus der gemeinsamen Dichte $f_{X,Y}$ kann man ableiten \\
$f_X(x) = \sum_{y \in W_Y} f_{X,Y} (x,y)$ \\
$f_Y(x) = \sum_{x \in W_X} f_{X,Y} (x,y)$ \\
Die Funktionen f_X und f_Y nennt man Randdichten. \\
*** Unabhängigkeit von Zufallsvariablen
**** Definition 45
Die Zufallsvariablen $X_1,...,X_n$ heißen unabhängig, wenn für alle $(x_1,...x_n) \in W_{X_1} \times ... \times W_{X_n}$ gilt: \\
$Pr[X_1 = x_1,...,X_n = x_n] = Pr[X_1 = x_1] * ... * Pr[X_n = x_n]$

Analog: Gesamte Dichte ist Produkt aus einzelnen Dichten.
Analog: Gesamte Verteilung ist Produkt aus einzelnen Verteilungen.

*** Zusammengesetzte Zufallsvariablen
**** Satz 49
Für zwei unabhängige Zufallsvariablen X und Y sei Z := X + Y . Es gilt
$f_Z(z) = \sum_{x \in W_X} f_X(x) * f_Y(z - x)$

*** Momente zusammengesetzter Zufallsvariablen
**** Satz 50 (Linearität des Erwartungswerts)
Für Zufallsvariablen $X_1,...,X_n$ und $X:=a_1X_1 + ... + a_nX_n$ mit $a_1, ...a_n \in R$ gilt \\
$\mathbb{E}[X] = a_1 \mathbb{E}[X_1]+ ... + a_n\mathbb{E}[X_n]$

**** Satz 52 (Multiplikativität des Erwartungswerts)
Für unabhängige Zufallsvariablen $X_1,..., X_n$ gilt
$E[X1*...*Xn] = E[X1]*...*E[Xn]$

**** Definition 53
Zu einem Ereignis A heißt die Zufallsvariable \\
$I_A = \begin{array}{ll}  1 & \, \textrm{falls A eintritt} \\ 0 & \, \textrm{sonst} \\\end{array}$ \\
*Indikatorvariable* des Ereigniss A

* Wichtige diskrete Verteilungen

** Bernoulli Verteilung
Eine Zufallsvariable X mit $W_X = {0, 1}$ und der Dichte
$f_X(x) = \left\{ \begin{array}{ll} p & x = 1 \\ 1-p & x = 0 \\ \end{array} \right$

heißt Bernoulli-verteilt. Den Parameter p nennen wir Erfolgswahrscheinlichkeit.
Eine solche Verteilung erhält man z.B. bei einer einzelnen Indikatorvariablen. Es gilt mir $q := p-1$
$E[X] = p$ und $Var[X] = pq$,
wegen $E[X^2] = p$ und $Var[X] = E[X^2] − E[X]^2 = p − p^2$.
** Binomialverteilung
Eine Bernoulli-verteilte Zufallsvariable entspricht der Verteilung einer Indikatorvariablen. Häufig betrachtet man jedoch Summen von Indikatorvariablen.
*** Definition 55
Sei $X := X_1 + ... + X_n$ als Summe von n unabhängigen, Bernoulli-verteilten Zufallsvariablen mit gleicher Erfolgswahrscheinlichkeit p definiert. Dann heißt X binomialverteilt mit den Parametern n und p. In Zeichen schreiben wir
$X \sim Bin(n,p)$ \\
$Pr[X=k] = \begin{pmatrix} n \\ k \end{pmatrix} * p^k * (1-p)^{n-k}$
*** Satz 56
Wenn $X \sim Bin(n_x, p)$ und $Y \sim Bin(n_y, p)$ unabhängig sind, dann gilt für $Z := X + Y$ , dass $Z \sim Bin(n_x + n_y, p)$.
** 5.3 Geometrische Verteilung
Man betrachte ein Experiment, das so lange wiederholt wird, bis Erfolg eintritt. Gelingt ein einzelner Versuch mit Wahrscheinlichkeit p, so ist die Anzahl der Versuche bis zum Erfolg geometrisch verteilt.
*** Definition 57
Eine geometrisch verteilte Zufallsvariable X mit Parameter (Erfolgswahrscheinlichkeit)
$p \in (0, 1]$ und $q := 1 - p$ hat die Dichte
$f_X(i) = pq^{i-1}$ für $i \in \mathbb{N}$ .
Für Erwartungswert und Varianz geometrisch verteilter Zufallsvariablen gilt: \\
$E[X] = \frac{1}{p}$ und $Var[X] = \frac{q}{p^2}$
*** Wegen gedächnislosigkeit:
$Pr[X = n+k | X > n] = Pr[X=k]$ \\
$Pr[X > n+k | X > n] = Pr[X>k]$
*** Warten auf n-ten Erfolg
$f_Z(z) = \begin{pmatrix} z - 1 \\ n - 1 \end{pmatrix} * p^n(1-p) (1-p)^{z-n}$
** Poisson-Verteilung
Die Poisson-Verteilung kann verwendet werden, um die Anzahl von Ereignissen zu
modellieren, welche mit konstanter Rate und unabhängig voneinander in einem
Zeitintervall auftreten.
Eine Poisson-verteilte Zufallsvariable X mit dem Parameter $\lambda \geq 0$ hat den
Wertebereich $W_X = \mathbb{N}_0$ und besitzt die Dichte
$f_X(i) = \frac{e^{-\lambda}\lambda^i}{i!}$ für $i \in \mathbb{N}_0$. \\
Als Erwartungswert ergibt sich: \\
$\mathbb{E}[X] = \lambda$ \\
Und für die Varianz: \\
$Var[X] = \lambda$
*** 5.4.1 Poisson-Verteilung als Grenzwert der Binomialverteilung
Wir betrachten eine Folge von binomialverteilten Zufallsvariablen $X_n$ mit
$X_n \sim Bin(n, p_n)$, wobei $p_n = \lambda/n$. Für ein beliebiges k mit $0 \leq k \leq n$ ist die Wahrscheinlichkeit, dass $X_n$ den Wert k annimmt gleich: \\
$b(k;n,p_n) = \frac{\lambda^k}{k!} * \frac{n^{\underline{k}}}{n^k} (1-\frac{\lambda}{n})^{n-k}$ \\
Damit folgt: \\
$\lim_{n \rightarrow \infty} b(k;n,p_n) = e^{-\lambda} * \frac{\lambda^k}{k!}$

*** Satz 59
Sind X und Y unabhängige Zufallsvariablen mit $X \sim Po(\lambda)$ und $Y \sim Po(\mu)$, dann gilt \\
$Z := X + Y  \sim Po(\lambda + \mu)$

* Abschätzen von Wahrscheinlichkeiten
** Satz 60: Markov-Ungleichung
Sei /X/ eine Zufallsvariable die nur nicht negative Werte annimmt. Dann gilt für alle $t\in \mathbb{R}$ mit $t > 0$, dass
#+BEGIN_CENTER
$Pr[X>t] \le \frac{\mathbb{E}[X]}{t}$
#+END_CENTER
Äquivalent dazu: $Pr[X>t \bullet \mathbb{E}[X]] \le 1/t$

** Satz 61: Chebyshev-Ungleichung
Sei /X/ eine Zufallsvariable, und sei $t\in \mathbb{R}$ mit $t>0$. Dann gilt
#+BEGIN_CENTER
$Pr[|X-\mathbb{E}[X]| \ge t] \le \frac{Var[X]}{t^2}$
#+END_CENTER
Äquivalent dazu: $Pr[|X-\mathbb{E}[X]|\ge t\sqrt{Var[X]}] \le 1/t^2$

** Satz 62: Gesetz der großen Zahlen
Gegeben sei eine Zufallsvariable /X/ & seien $\epsilon, \delta > 0$  beliebig aber fest. Dann gilt für alle $n\ge \frac{Var[X]}{\epsilon \delta^2}$ \\
Sind $X_1, ..., X_n$ unabhängige Zufallsvariablen mit derselben Verteilung wie /X/ und setzt man $Z:= \frac{X_1 + ... + X_n}{n}$ \\
so gilt $Pr[|Z-\mathbb{E}[X]| \ge \delta] \le \epsilon$

*** Wahrscheinlichkeit und relative Häufigkeit
*TODO*: /slide 161/

** Chernoff-Schranken


* Erzeugende Funktionen
** Wahrscheinlichkeitserzeugende Funktion
Für eine Zufallsvariable /X/ mit $W_X \subseteq \mathbb{N}_0$ ist die *wahrscheinlichkeitserzeugende Funktion* definiert durch \\
$G_X(s) := \sum_{k=0}^\infty Pr[X=k] * s^k = \mathbb{E}[s^X]$
*** Satz 71 (Eindeutigkeit der w.e. Funktion)
Die Dichte und die Verteilung einer Zufallsvariablen $X$ mit $W_X \subseteq \mathbb{N}$ sind durch ihre /wahrscheinlichkeitserzeugenden Funktion bestimmt/
*** Bernoulliverteilung
**** Für binäre zufallsvariable X:
$G_X(s) = E[s^X] = (1 − p) * s_0 + p * s_1 = 1 - p + ps$
**** Gleichverteilung auf ${0,...,n}$
Dann gilt
$G_X(s) = E[s^X] = \sum_{k=0}^n \frac{1}{n + 1}*  s^k = \frac{s^{n+1} − 1}{}(n + 1)(s − 1)}$
*** Binomialverteilung
$G_X(s) = E[s^X] = \sum_{k=0}^n \begin{pmatrix} n \\ k \end{pmatrix} p^k (1-p)^{n-k} * s^k = (1-p+ps)^n$
*** Geometrische Verteilung
$G_X(s) = E[s^X] = \frac{ps}{1-(1-p)s}$
*** Poisson Verteilung
$G_X(s) = E[s^X] = e^{\lambda(s-1)}$

** Momenterzeugende Funktion
$M_X(s) := \mathbb{E}[e^{Xs}] = \mathbb{E}[\sum_{i=0}^\infty \frac{(Xs)^i}{i!} = \mathbb{E}[\sum_{i=0}^\infty \frac{\mathbb{E}[X^i]}{i!}$ \\
und für Zufallsvariablen $X$ mit $W_X \subseteq \mathbb{N}_0$ \\
$MX(s) = E[e^{Xs}] = E[(e^s)^X] = G_X(e^s)$
*** Summe von Zufallsvariablen
Für unabhängige Zufallsvariablen $X_1,..., X_n$ und die Zufallsvariable \\
$Z := X_1 + ... + X_n$ gilt \\
$G_Z(s) = G_{X_1}(s) * ... * G_{X_n}(s)$ \\
Ebenso gilt
$M_Z(s) = M_{X_1}(s) * ... * M_{X_n}(s)$
** Zufällige Summen
Wir betrachten die Situation, dass $Z := X_1 + ... + X_N$, wobei $N$ ebenfalls eine Zufallsvariable ist
*** Satz 77
Seien $X_1, X_2,... unabhängige und identisch verteilte Zufallsvariablen mit der wahrscheinlichkeitserzeugenden Funktion $GX(s)$. \\
$N$ sei ebenfalls eine unabhängige Zufallsvariable mit der wahrscheinlichkeitserzeugenden Funktion $G_N(s)$. Dann besitzt die Zufallsvariable $Z := X_1 + ... + X_N$ die wahrscheinlichkeitserzeugende Funktion $G_Z(s) = G_N(G_X(s))$

* Formelsammlung
** Gesetze zum Rechnen mit Ereignissen
($A \uplus B \ \hat{=}$ disjunkte Vereinigung)
- $Pr[\emptyset] = 0$
- $0 \leq Pr[A] \leq 1$
- $Pr[\overline{A}] = 1 - Pr[A]$
- $A \subseteq B \implies Pr[A] \leq Pr[B]$
- $\forall i \neq j: A_i \cap A_j = \emptyset \implies Pr[\bigcup_{i=1}^n A_i] = \sum_{i=1}^n A_i$ (Additionssatz)
- $Pr[A \cup B] = Pr[A] + Pr[B] - Pr[A \cap B]$ (Siebformel)
- $Pr[\bigcup_{i=1}^n A_i] \leq \sum_{i=1}^n A_i$ (Boolsche Ungleichung)
- $Pr[A|B] = \frac{Pr[A \cup B]}{Pr[B]}$ für $Pr[B] > 0$ (Def. bedingte ws.)
- $B \subseteq A_1 \uplus ... \uplus A_n \implies Pr[B] = \sum_{i=1}^n Pr[B|A_i] * Pr[A_i]$ (Satz der totalen Wahrscheinlichkeit)
- $Pr[B] > 0, B \subseteq A_1 \uplus ... \uplus A_n \implies Pr[A_i|B] = \frac{Pr[B|A_i] * Pr[A_i]}{\sum_{i=1}^nPr[B|A_i] * A_i}$ (Satz von Bayes)
- $Pr[A_1 \cap ... \cap A_n] = Pr[A_1] * Pr[A_2|A_1] * Pr[A_n | A_1 \cap ... \cap A_{n-1}]$ (Multiplikationssatz)
- $A$ und $B$ unabhängig $\iff Pr[A \cap B] = A * B$
** Erwartungswert und Varianz diskreter Zufallsvariablen
- $E[X] = \sum_{x \in W_X} x * Pr[X = x]$ \\
  $\sum_{\omega \in \Omega} X(\omega) * Pr[\omega]$ \\
  ($= \sum_{i=1} Pr[X \geq i]$ , falls $W_X \subseteq \mathbb{N}_0$) (Erwartungswert)
- $Var[X] = \mathbb{E}[(X - \mathbb{E}[X])^2]$ \\
  $\sum_{x \in W_X} Pr[X = x] * (x - \mathbb{E}[X])^2$ (Varianz)
** Gesetze zum Rechnen mit Zufallsvariablen
Seien $a, b, a_1,..., a_n \in \mathbb{R}, f_1,..., f_n : \mathbb{R} \rightarrow \mathbb{R}$. $X1,...,Xn$ unabhängig
- $X_1, ..., X_n$ unabhängig \\
  $\iff \ \forall (a_1,...,a_n): Pr[X_1 = a_1, ..., X_n = a_n] = Pr[X_1 = a_1] * ... * Pr[X_n = a_n]$

- $X_1, ..., X_n$ unabhängig \\
  $\implies f_1(X_1), ..., f_n(X_n)$ unabhängig

- $\mathbb{E}[a * X + b] = a * \mathbb{E}[X] + b$

- $X(\omega) \leq Y(\omega) \forall \omega \in \Omega \implies \mathbb{E}[X] \leq \mathbb{E}[Y]$

- $\mathbb{E}[X] = \sum_{i=1}^n \mathbb{E}[X | A_i] * Pr[A_i]$

- $Var[X] = \mathbb{E}[X^2] - \mathbb{E}[X]^2$

- $Var[a * X + b] = a^2 * Var[X]$

- $\mathbb{E}[a_1X_1 + ... + a_nX_n] = a_1E[X_1] + ... + a_nE[X_n]$ (Liniarität des Erwartungswerts)

- $X_1, ..., X_n$ unabhängig $\implies E[X_1 * ... * X_n] = E[X_1] * ... * E[X_n]$ (Multiplikativität des Erwartungswerts)

- $X_1, ..., X_n$ unabhängig $\implies Var[X_1 + ... + X_n] = Var[X_1] + ... + Var[X_n]$ (Varianz einer Summe)

- $X \geq 0 \implies Pr[X \geq t] \leq E[X]/t$ für $t > 0$ (Markov)

- $Pr[|X − E[X]| \geq t] \leq Var[X]/t_2$ für $t > 0$
